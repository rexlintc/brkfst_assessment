{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4564da57-60a8-4931-8279-f845382de0cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'smolagents'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msmolagents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CodeAgent, DuckDuckGoSearchTool, HfApiModel\n\u001b[32m      3\u001b[39m model = HfApiModel()\n\u001b[32m      4\u001b[39m agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=model)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'smolagents'"
     ]
    }
   ],
   "source": [
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, HfApiModel\n",
    "\n",
    "model = HfApiModel()\n",
    "agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=model)\n",
    "\n",
    "agent.run(\"How many seconds would it take for a leopard at full speed to run through Pont des Arts?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa34ad31-4753-43d1-b07b-ea61a188ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "from playwright.sync_api import sync_playwright\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class TikTokScraper:\n",
    "    def __init__(self, download_path: str = \"downloads\"):\n",
    "        \"\"\"Initialize TikTok scraper.\n",
    "        \n",
    "        Args:\n",
    "            download_path (str): Path to save downloaded videos\n",
    "        \"\"\"\n",
    "        self.download_path = download_path\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        }\n",
    "        os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "    def scrape_user(self, username: str, limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"Scrape videos from a user's profile.\n",
    "        \n",
    "        Args:\n",
    "            username (str): TikTok username\n",
    "            limit (int): Maximum number of videos to scrape\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: List of video metadata\n",
    "        \"\"\"\n",
    "        with sync_playwright() as p:\n",
    "            browser = p.chromium.launch(headless=True)\n",
    "            page = browser.new_page()\n",
    "            \n",
    "            # Navigate to user's profile\n",
    "            page.goto(f\"https://www.tiktok.com/@{username}\")\n",
    "            page.wait_for_load_state(\"networkidle\")\n",
    "            \n",
    "            videos = []\n",
    "            last_height = page.evaluate(\"document.documentElement.scrollHeight\")\n",
    "            \n",
    "            with tqdm(total=limit, desc=f\"Scraping @{username}'s videos\") as pbar:\n",
    "                while len(videos) < limit:\n",
    "                    # Extract video information\n",
    "                    new_videos = page.evaluate(\"\"\"\n",
    "                        () => {\n",
    "                            const videos = document.querySelectorAll('div[data-e2e=\"user-post-item\"]');\n",
    "                            return Array.from(videos).map(video => {\n",
    "                                const link = video.querySelector('a');\n",
    "                                const desc = video.querySelector('div[data-e2e=\"user-post-item-desc\"]');\n",
    "                                return {\n",
    "                                    url: link ? link.href : null,\n",
    "                                    description: desc ? desc.innerText : null,\n",
    "                                    timestamp: new Date().toISOString()\n",
    "                                }\n",
    "                            });\n",
    "                        }\n",
    "                    \"\"\")\n",
    "                    \n",
    "                    videos.extend([v for v in new_videos if v[\"url\"] and v not in videos])\n",
    "                    pbar.update(len(new_videos))\n",
    "                    \n",
    "                    # Scroll down\n",
    "                    page.evaluate(\"window.scrollTo(0, document.documentElement.scrollHeight)\")\n",
    "                    page.wait_for_timeout(1000)  # Wait for content to load\n",
    "                    \n",
    "                    new_height = page.evaluate(\"document.documentElement.scrollHeight\")\n",
    "                    if new_height == last_height:\n",
    "                        break\n",
    "                    last_height = new_height\n",
    "            \n",
    "            browser.close()\n",
    "            return videos[:limit]\n",
    "\n",
    "    async def download_video(self, video_url: str, output_path: str):\n",
    "        \"\"\"Download a TikTok video.\n",
    "        \n",
    "        Args:\n",
    "            video_url (str): URL of the video\n",
    "            output_path (str): Path to save the video\n",
    "        \"\"\"\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(video_url, headers=self.headers) as response:\n",
    "                if response.status == 200:\n",
    "                    with open(output_path, 'wb') as f:\n",
    "                        while True:\n",
    "                            chunk = await response.content.read(1024)\n",
    "                            if not chunk:\n",
    "                                break\n",
    "                            f.write(chunk)\n",
    "\n",
    "    def scrape_hashtag(self, hashtag: str, limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"Scrape videos from a hashtag.\n",
    "        \n",
    "        Args:\n",
    "            hashtag (str): Hashtag to scrape (without #)\n",
    "            limit (int): Maximum number of videos to scrape\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: List of video metadata\n",
    "        \"\"\"\n",
    "        with sync_playwright() as p:\n",
    "            browser = p.chromium.launch(headless=True)\n",
    "            page = browser.new_page()\n",
    "            \n",
    "            # Navigate to hashtag page\n",
    "            page.goto(f\"https://www.tiktok.com/tag/{hashtag}\")\n",
    "            page.wait_for_load_state(\"networkidle\")\n",
    "            \n",
    "            videos = []\n",
    "            last_height = page.evaluate(\"document.documentElement.scrollHeight\")\n",
    "            \n",
    "            with tqdm(total=limit, desc=f\"Scraping #{hashtag} videos\") as pbar:\n",
    "                while len(videos) < limit:\n",
    "                    # Extract video information\n",
    "                    new_videos = page.evaluate(\"\"\"\n",
    "                        () => {\n",
    "                            const videos = document.querySelectorAll('div[data-e2e=\"challenge-item\"]');\n",
    "                            return Array.from(videos).map(video => {\n",
    "                                const link = video.querySelector('a');\n",
    "                                const desc = video.querySelector('div[data-e2e=\"challenge-item-desc\"]');\n",
    "                                return {\n",
    "                                    url: link ? link.href : null,\n",
    "                                    description: desc ? desc.innerText : null,\n",
    "                                    timestamp: new Date().toISOString()\n",
    "                                }\n",
    "                            });\n",
    "                        }\n",
    "                    \"\"\")\n",
    "                    \n",
    "                    videos.extend([v for v in new_videos if v[\"url\"] and v not in videos])\n",
    "                    pbar.update(len(new_videos))\n",
    "                    \n",
    "                    # Scroll down\n",
    "                    page.evaluate(\"window.scrollTo(0, document.documentElement.scrollHeight)\")\n",
    "                    page.wait_for_timeout(1000)  # Wait for content to load\n",
    "                    \n",
    "                    new_height = page.evaluate(\"document.documentElement.scrollHeight\")\n",
    "                    if new_height == last_height:\n",
    "                        break\n",
    "                    last_height = new_height\n",
    "            \n",
    "            browser.close()\n",
    "            return videos[:limit]\n",
    "\n",
    "    def save_metadata(self, metadata: List[Dict], filename: str):\n",
    "        \"\"\"Save metadata to CSV file.\n",
    "        \n",
    "        Args:\n",
    "            metadata (List[Dict]): List of video metadata\n",
    "            filename (str): Output filename\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(metadata)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Metadata saved to {filename}\")\n",
    "\n",
    "    async def download_videos(self, metadata: List[Dict]):\n",
    "        \"\"\"Download videos from metadata.\n",
    "        \n",
    "        Args:\n",
    "            metadata (List[Dict]): List of video metadata\n",
    "        \"\"\"\n",
    "        tasks = []\n",
    "        for i, video in enumerate(metadata):\n",
    "            if video[\"url\"]:\n",
    "                output_path = os.path.join(self.download_path, f\"video_{i}.mp4\")\n",
    "                task = asyncio.create_task(self.download_video(video[\"url\"], output_path))\n",
    "                tasks.append(task)\n",
    "        \n",
    "        await asyncio.gather(*tasks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "698f0352-1b24-4669-b394-c8c364abe6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rex/brkfst_assessment\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8825b4-a1d6-4aca-89f0-25fce798300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = TikTokScraper(download_path=\"downloaded_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b119b-78f3-4f24-af86-9fcd690f7ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from tiktok_scraper import TikTokScraper\n",
    "\n",
    "async def main():\n",
    "    # Initialize the scraper\n",
    "    scraper = TikTokScraper(download_path=\"downloaded_videos\")\n",
    "    \n",
    "    # Example 1: Scrape videos from a user's profile\n",
    "    print(\"Scraping user profile...\")\n",
    "    user_videos = scraper.scrape_user(\"tiktok\", limit=5)  # Replace with any username\n",
    "    scraper.save_metadata(user_videos, \"user_videos_metadata.csv\")\n",
    "    \n",
    "    # Download the videos\n",
    "    print(\"Downloading user videos...\")\n",
    "    await scraper.download_videos(user_videos)\n",
    "    \n",
    "    # Example 2: Scrape videos from a hashtag\n",
    "    print(\"\\nScraping hashtag...\")\n",
    "    hashtag_videos = scraper.scrape_hashtag(\"python\", limit=5)  # Replace with any hashtag\n",
    "    scraper.save_metadata(hashtag_videos, \"hashtag_videos_metadata.csv\")\n",
    "    \n",
    "    # Download the videos\n",
    "    print(\"Downloading hashtag videos...\")\n",
    "    await scraper.download_videos(hashtag_videos)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
